{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-shot face recognition tutorial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial based on this [video](https://www.youtube.com/watch?v=LKispFFQ5GU) will use tensorflow v2 to create a face recognition model based on the one-shot architecture. <br/>\n",
    "\n",
    "The steps are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import all the shared libraries that notebook uses section-wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from typing import Tuple, Final, Any\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a workspace with all the necessary folders in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All necessary folders created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "WORKSPACE_DIR_PATH: Final[str] = 'tutorial_workspace'\n",
    "DOWNLOADS_PATH: Final[str] = path.join(WORKSPACE_DIR_PATH, 'downloads')\n",
    "ANCHORS_PATH: Final[str] = path.join(WORKSPACE_DIR_PATH, 'anchors')\n",
    "POSITIVES_PATH: Final[str] = path.join(WORKSPACE_DIR_PATH, 'positives')\n",
    "NEGATIVES_PATH: Final[str] = path.join(WORKSPACE_DIR_PATH, 'negatives')\n",
    "OUTPUTS_PATH: Final[str] = path.join(WORKSPACE_DIR_PATH, 'outputs')\n",
    "\n",
    "os.makedirs(DOWNLOADS_PATH, exist_ok=True)\n",
    "os.makedirs(ANCHORS_PATH, exist_ok=True)\n",
    "os.makedirs(POSITIVES_PATH, exist_ok=True)\n",
    "os.makedirs(NEGATIVES_PATH, exist_ok=True)\n",
    "os.makedirs(OUTPUTS_PATH, exist_ok=True)\n",
    "\n",
    "print('All necessary folders created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fetching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model a dataset is necessary. <br/>\n",
    "For that we will use the `LFW` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will use named `LFW` and you can find it either in this [link](http://vis-www.cs.umass.edu/lfw/#download) or at the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import requests\n",
    "\n",
    "TAR_URL: Final[str] = 'http://vis-www.cs.umass.edu/lfw/lfw.tgz'\n",
    "FILE_NAME: Final[str] = 'lfw.tgz'\n",
    "file_path: str = path.join(DOWNLOADS_PATH, FILE_NAME)\n",
    "\n",
    "if not path.exists(file_path):\n",
    "    # Make an HTTP request within a context manager\n",
    "    with requests.get(TAR_URL, stream=True) as r:\n",
    "        \n",
    "        # Check header to get content length, in bytes\n",
    "        total_length = int(r.headers.get(\"Content-Length\"))\n",
    "        \n",
    "        # Implement progress bar via tqdm\n",
    "        with tqdm.wrapattr(r.raw, \"read\", total=total_length, desc=\"lfw.tar compressed dataset\") as raw:\n",
    "        \n",
    "            # Save the output to a file\n",
    "            with open(file_path, 'wb')as output:\n",
    "                shutil.copyfileobj(raw, output)\n",
    "else:\n",
    "    print('Dataset already downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described above, the model needs a lot faces that not match to the anchors. <br/>\n",
    "For that we will use the dataset we downloaded above.\n",
    "\n",
    "So, we will extract the compressed files. and put them into the `NEGATIVES_PATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13233/13233 [01:22<00:00, 159.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "from typing import IO, Iterable\n",
    "\n",
    "file_path: str = path.join(DOWNLOADS_PATH, 'lfw.tgz')\n",
    "\n",
    "with tarfile.open(file_path, 'r:gz') as compressed_file:\n",
    "    # Filtering out all directories and non-jpg files\n",
    "    all_members: Iterable[tarfile.TarInfo] = [m for m in compressed_file.getmembers() if '.jpg' in m.name or '.png' in m.name]\n",
    "    \n",
    "    for member in tqdm(iterable=all_members, total=len(all_members)):\n",
    "        archive_filename: str = member.path.split('/')[-1]\n",
    "        filename: str = path.join(NEGATIVES_PATH, archive_filename)\n",
    "        \n",
    "        buffer_reader: IO[bytes] = compressed_file.extractfile(member)\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(buffer_reader.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect positive and anchors data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, we successfully loaded the `LFW` dataset into our workspace as negative shots (observations).\n",
    "\n",
    "Now, let's dive into the positives.\n",
    "So, we can get those observations in many ways. Like taking shots from the camera, use existing images. <br/>\n",
    "Let's do both!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking shots from webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we take shots from the camera, we need to remember. The dataset has 250x250 pixels images. <br/>\n",
    "For the simplicity of this project, we will preffer to use the exact same size with the new shots.\n",
    "\n",
    "So remember, 250x250..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to import necessary packages for that phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "WINDOW_NAME: str = 'Webcam Calibration'\n",
    "first_loop: bool = True\n",
    "is_device_connected: bool = cap.isOpened()\n",
    "original_frame = None\n",
    "\n",
    "rect_start_x = None\n",
    "rect_start_y = None\n",
    "rect_end_x = None\n",
    "rect_end_y = None\n",
    "\n",
    "print(f\"The device is { 'connected' if is_device_connected else 'disconnected' }\")\n",
    "\n",
    "def click_and_draw(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        global rect_start_x, rect_start_y, rect_end_x, rect_end_y\n",
    "        \n",
    "        crop_width = 250\n",
    "        crop_height = 250\n",
    "\n",
    "        rect_start_x = int(x - crop_width / 2)\n",
    "        rect_start_y = int(y - crop_height / 2)\n",
    "        rect_end_x = int(x + crop_height / 2)\n",
    "        rect_end_y = int(y + crop_height / 2)\n",
    "\n",
    "while is_device_connected:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    original_frame = frame\n",
    "    _frame = copy.deepcopy(frame)\n",
    "    if rect_start_x != None and rect_start_y != None:\n",
    "        cv2.rectangle(_frame, (rect_start_x, rect_start_y), (rect_end_x, rect_end_y), (0, 0, 255), 5)\n",
    "    \n",
    "    cv2.imshow(WINDOW_NAME, _frame)\n",
    "    \n",
    "    if first_loop:\n",
    "        cv2.setMouseCallback(WINDOW_NAME, click_and_draw)\n",
    "        first_loop = False\n",
    "\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "\n",
    "if rect_start_x and rect_start_y:\n",
    "    plt.imshow(original_frame[rect_start_y:rect_end_y, rect_start_x:rect_end_x, :])\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is connected\n"
     ]
    }
   ],
   "source": [
    "# In case it not working properly, you can try with different index\n",
    "cap = cv2.VideoCapture(0)\n",
    "is_device_connected: bool = cap.isOpened()\n",
    "print(f\"The device is { 'connected' if is_device_connected else 'disconnected' }\")\n",
    "while is_device_connected:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Cut a 250x250 pixels crop from the original feed\n",
    "    # start_x: int = 200\n",
    "    # start_y: int = 120\n",
    "    # height: int = start_y + 250\n",
    "    # width: int = start_x + 250\n",
    "    # frame = frame[start_x:width, start_y:height, :]\n",
    "    frame = frame[rect_start_y:rect_end_y, rect_start_x:rect_end_x, :]\n",
    "\n",
    "    # Collect anchor image\n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        # Creating unique filename\n",
    "        generated_name: str = f'{uuid.uuid1()}.jpg'\n",
    "        img_name: str = path.join(ANCHORS_PATH, generated_name)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "\n",
    "    # Collect positive image\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        # Creating unique filename\n",
    "        generated_name: str = f'{uuid.uuid1()}.jpg'\n",
    "        img_name: str = path.join(POSITIVES_PATH, generated_name)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "\n",
    "    # Show image back to screen\n",
    "    cv2.imshow('Image collection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Frame shape:', frame.shape)\n",
    "plt.title('Last frame detected')\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In case the code above not working"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you don't know which `device id` to use in the opencv's video `device id`. <br />\n",
    "Let's search for all the devices available to take images from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing index 0\n",
      "Port 0 is working and reads images (480.0 x 640.0)\n",
      "Testing index 1\n",
      "Port 1 is not working.\n",
      "Testing index 2\n",
      "Port 2 is not working.\n",
      "Testing index 3\n",
      "Port 3 is not working.\n",
      "Testing index 4\n",
      "Port 4 is not working.\n",
      "Testing index 5\n",
      "Port 5 is not working.\n",
      "Testing index 6\n",
      "Port 6 is not working.\n",
      "([], [0], [1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "def list_ports():\n",
    "    \"\"\"\n",
    "        Test the ports and returns a tuple with the available ports and the ones that are working.\n",
    "    \"\"\"\n",
    "    non_working_ports = []\n",
    "    dev_port = 0\n",
    "    working_ports = []\n",
    "    available_ports = []\n",
    "    while len(non_working_ports) < 6: # if there are more than 5 non working ports stop the testing. \n",
    "        print(f'Testing index {dev_port}')\n",
    "        camera = cv2.VideoCapture(dev_port)\n",
    "        if not camera.isOpened():\n",
    "            non_working_ports.append(dev_port)\n",
    "            print(\"Port %s is not working.\" %dev_port)\n",
    "        else:\n",
    "            is_reading, img = camera.read()\n",
    "            w = camera.get(3)\n",
    "            h = camera.get(4)\n",
    "            if is_reading:\n",
    "                print(\"Port %s is working and reads images (%s x %s)\" %(dev_port,h,w))\n",
    "                working_ports.append(dev_port)\n",
    "            else:\n",
    "                print(\"Port %s for camera ( %s x %s) is present but does not reads.\" %(dev_port,h,w))\n",
    "                available_ports.append(dev_port)\n",
    "        dev_port +=1\n",
    "    return available_ports,working_ports,non_working_ports\n",
    "\n",
    "print(list_ports())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from existing images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternitivly, you can load the positive and anchors images from existing images files. <br/>\n",
    "Just copy your images positive images into `$POSITIVES_PATH`, and the anchors will be copied into `ANCHORS_PATH`.\n",
    "\n",
    "Don't forget to make sure that the photos you are importing have to be at shape (resolution) of `250px*250px`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data successfully collected. Let's start to prepare it to the training phase.\n",
    "\n",
    "So, what we will do in this phase is:\n",
    "* Create labeled dataset from the anchors, positives and negatives directories\n",
    "* Split the dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import tensorflow as tf\n",
    "from tf_agents.typing.types import EagerTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that all of the images we will going to use, having the same 'shape' (dimensions). <br/>\n",
    "In case they are different, we will scale them to the apropriate dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.data.ops.dataset_ops._NumpyIterator at 0x22d52ec28f0>,\n",
       " <tensorflow.python.data.ops.dataset_ops._NumpyIterator at 0x22d52ec23b0>,\n",
       " <tensorflow.python.data.ops.dataset_ops._NumpyIterator at 0x22d52ec06a0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_SIZE: Final[int] = 300\n",
    "\n",
    "# Tensorflow will take all files matching to the pattern inside `list_files()`\n",
    "anchor: tf.data.Dataset = tf.data.Dataset.list_files(f'{ANCHORS_PATH}/*.jpg').take(DATASET_SIZE)\n",
    "positive: tf.data.Dataset = tf.data.Dataset.list_files(f'{POSITIVES_PATH}/*.jpg').take(DATASET_SIZE)\n",
    "negative: tf.data.Dataset = tf.data.Dataset.list_files(f'{NEGATIVES_PATH}/*.jpg').take(DATASET_SIZE)\n",
    "\n",
    "negative.as_numpy_iterator(), anchor.as_numpy_iterator(), positive.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: This how you can iterate over a tensorlow Dataset class (in this case we will run over the anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'tutorial_workspace\\\\anchors\\\\dd00e728-9cb0-11ed-b04f-b808cf4c5169.jpg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale and resize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path: str):\n",
    "    '''\n",
    "        This function will load with tensorflow this image\n",
    "        and resize it to the apropriate dimensions needed for our neural network.\n",
    "        \n",
    "        args:\n",
    "            file_path: str - path to the target image file\n",
    "\n",
    "        returns: \n",
    "            2d array of the pixels of the image \n",
    "    '''\n",
    "\n",
    "    # Read image bytes from file path\n",
    "    byte_image = tf.io.read_file(file_path)\n",
    "    \n",
    "    # Loading the bytes as image\n",
    "    image = tf.io.decode_jpeg(byte_image)\n",
    "\n",
    "    # Resize the image to 100x100 pixels\n",
    "    image: EagerTensor = tf.image.resize(image, (100, 100))\n",
    "    \n",
    "    # Devide each pixel between (0 and 1) instead of (0 and 255)\n",
    "    image /= 255.0\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be sure, let's verify that the pre process have done successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate one of the lists \n",
    "_dup_anchor = anchor.as_numpy_iterator()\n",
    "\n",
    "# Running the preprocess on the current image\n",
    "img = preprocess(_dup_anchor.next())\n",
    "\n",
    "print('Minimum value in tensor (should be 0):', img.numpy().min())\n",
    "print('Max value in tensor (should be 1):', img.numpy().max())\n",
    "print('Image shape (should be (100, 100, 3)):', img.numpy().shape)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the labeled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model, we will need to give it:\n",
    "* Positive observations (which means anchor image, positive image and result of 1).\n",
    "* Negative observations (which means anchor image, negative and result of 0).\n",
    "\n",
    "For that we will create two datasets, one for positive and one for negative. And concatenate them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_labels = tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor))) # Create a vector with shape of positive images\n",
    "negative_labels = tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor))) # Create a vector with shape of negative images\n",
    "\n",
    "# Telling the data loader to load each of those images with the proper label simultaneously \n",
    "positive_dataset = tf.data.Dataset.zip((anchor, positive, positive_labels))\n",
    "negative_dataset = tf.data.Dataset.zip((anchor, negative, negative_labels))\n",
    "\n",
    "# Concatenating the positive and negative datasets into a single dataset\n",
    "dataset = positive_dataset.concatenate(negative_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Little example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcatenateDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset.as_numpy_iterator()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'tutorial_workspace/anchors/df4405ef-9cb0-11ed-ac81-b808cf4c5169.jpg',\n",
       " b'tutorial_workspace/positives/dae06dcf-9cb0-11ed-8f05-b808cf4c5169.jpg',\n",
       " 1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build train and test dataset partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load all the images from it's path, and put them the proper label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img: str, validation_img: str, label: int) -> tuple[Any, Any, int]:\n",
    "    return (preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
       " array([[[0.57254905, 0.60784316, 0.6039216 ],\n",
       "         [0.56764704, 0.6039216 , 0.6       ],\n",
       "         [0.5625    , 0.6017157 , 0.5977941 ],\n",
       "         ...,\n",
       "         [0.6245098 , 0.66764706, 0.6519608 ],\n",
       "         [0.6252451 , 0.66838235, 0.6526961 ],\n",
       "         [0.6237745 , 0.6669118 , 0.6512255 ]],\n",
       " \n",
       "        [[0.5732843 , 0.60857844, 0.6046569 ],\n",
       "         [0.56985295, 0.60612744, 0.6022059 ],\n",
       "         [0.5647059 , 0.6039216 , 0.6       ],\n",
       "         ...,\n",
       "         [0.6218137 , 0.66495097, 0.6492647 ],\n",
       "         [0.62647057, 0.6696078 , 0.65392154],\n",
       "         [0.61960787, 0.6627451 , 0.64705884]],\n",
       " \n",
       "        [[0.56642157, 0.6017157 , 0.5977941 ],\n",
       "         [0.5637255 , 0.6       , 0.59607846],\n",
       "         [0.5647059 , 0.6039216 , 0.6       ],\n",
       "         ...,\n",
       "         [0.6134804 , 0.65955883, 0.64387256],\n",
       "         [0.61740196, 0.6634804 , 0.6477941 ],\n",
       "         [0.6137255 , 0.6598039 , 0.64411765]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.11936274, 0.1115196 , 0.06446078],\n",
       "         [0.1127451 , 0.10686275, 0.05980392],\n",
       "         [0.09705883, 0.09705883, 0.05      ],\n",
       "         ...,\n",
       "         [0.17083333, 0.16004902, 0.09534314],\n",
       "         [0.18529412, 0.17450981, 0.10980392],\n",
       "         [0.14730392, 0.1375    , 0.06985294]],\n",
       " \n",
       "        [[0.11470588, 0.10686275, 0.05980392],\n",
       "         [0.10759804, 0.10171568, 0.05465686],\n",
       "         [0.1       , 0.1       , 0.05294118],\n",
       "         ...,\n",
       "         [0.15588236, 0.14803922, 0.08921569],\n",
       "         [0.16764706, 0.15980393, 0.10098039],\n",
       "         [0.11642157, 0.10955882, 0.04779412]],\n",
       " \n",
       "        [[0.10686275, 0.09901961, 0.05196078],\n",
       "         [0.10490196, 0.09901961, 0.05196078],\n",
       "         [0.10588235, 0.10588235, 0.05882353],\n",
       "         ...,\n",
       "         [0.14607844, 0.1382353 , 0.07941177],\n",
       "         [0.14411765, 0.13627452, 0.07745098],\n",
       "         [0.10294118, 0.09509804, 0.03627451]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
       " array([[[0.5686275 , 0.6156863 , 0.6156863 ],\n",
       "         [0.5598039 , 0.6068627 , 0.6068627 ],\n",
       "         [0.5561274 , 0.60318625, 0.60318625],\n",
       "         ...,\n",
       "         [0.61985296, 0.6669118 , 0.6669118 ],\n",
       "         [0.62352943, 0.67058825, 0.67058825],\n",
       "         [0.6186274 , 0.66568625, 0.66568625]],\n",
       " \n",
       "        [[0.56078434, 0.60588235, 0.6068627 ],\n",
       "         [0.55784315, 0.60294116, 0.6039216 ],\n",
       "         [0.56078434, 0.60588235, 0.6068627 ],\n",
       "         ...,\n",
       "         [0.61960787, 0.6666667 , 0.6666667 ],\n",
       "         [0.622549  , 0.6696078 , 0.6696078 ],\n",
       "         [0.62352943, 0.67058825, 0.67058825]],\n",
       " \n",
       "        [[0.56102943, 0.6002451 , 0.6041667 ],\n",
       "         [0.56078434, 0.6       , 0.6039216 ],\n",
       "         [0.5615196 , 0.6007353 , 0.6046569 ],\n",
       "         ...,\n",
       "         [0.6188725 , 0.66593134, 0.66593134],\n",
       "         [0.6166667 , 0.6637255 , 0.6637255 ],\n",
       "         [0.61960787, 0.6666667 , 0.6666667 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.10122549, 0.08946078, 0.05416667],\n",
       "         [0.10122549, 0.09117647, 0.05073529],\n",
       "         [0.11053921, 0.10269608, 0.05563726],\n",
       "         ...,\n",
       "         [0.09901961, 0.09901961, 0.05196078],\n",
       "         [0.07009804, 0.07009804, 0.02303922],\n",
       "         [0.09240196, 0.09240196, 0.04534314]],\n",
       " \n",
       "        [[0.09509804, 0.08627451, 0.04215686],\n",
       "         [0.10294118, 0.09509804, 0.04803922],\n",
       "         [0.12034313, 0.1125    , 0.06544118],\n",
       "         ...,\n",
       "         [0.07794118, 0.07794118, 0.03676471],\n",
       "         [0.07769608, 0.07769608, 0.03651961],\n",
       "         [0.10073529, 0.10073529, 0.05955882]],\n",
       " \n",
       "        [[0.09705883, 0.08921569, 0.04215686],\n",
       "         [0.11568628, 0.10784314, 0.06078431],\n",
       "         [0.11887255, 0.11102941, 0.06102941],\n",
       "         ...,\n",
       "         [0.06666667, 0.06666667, 0.02745098],\n",
       "         [0.07916667, 0.07916667, 0.03995098],\n",
       "         [0.09117647, 0.09117647, 0.05196078]]], dtype=float32)>,\n",
       " 1.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = sample.next()\n",
    "res = preprocess_twin(*example)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, after we have tested everything. Let's put all the things together. And build our dataloader pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset element_spec=(TensorSpec(shape=(100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(preprocess_twin) # Running all over the dataset with the `preprocess_twin` function\n",
    "dataset = dataset.cache() # Caching the images\n",
    "dataset = dataset.shuffle(buffer_size=1024) # Shuffling the dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = dataset.as_numpy_iterator().next()\n",
    "\n",
    "print('Label is:', samp[2])\n",
    "plt.imshow(samp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(samp[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make training and test dataset partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shared variables for this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_BATCH_SIZE: Final[int] = 16\n",
    "LEARNING_PREFETCH_SIZE: Final[int] = 8\n",
    "\n",
    "TRAIN_PARTITION_SIZE: Final[int] = round(len(dataset) * .7) # Get 70% of the dataset for training\n",
    "TEST_PARTITION_SIZE: Final[int] = round(len(dataset) * .3) # Get 30% of the dataset for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training partition setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data: tf.data.Dataset = dataset.take(TRAIN_PARTITION_SIZE)\n",
    "training_data: tf.data.Dataset = training_data.batch(LEARNING_BATCH_SIZE) # Set batch size of 16\n",
    "training_data: tf.data.Dataset = training_data.prefetch(LEARNING_PREFETCH_SIZE)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup testing partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data: tf.data.Dataset = dataset.skip(TRAIN_PARTITION_SIZE) # Skipping of all the training partition data\n",
    "test_data: tf.data.Dataset = test_data.take(TEST_PARTITION_SIZE)\n",
    "test_data: tf.data.Dataset = test_data.batch(LEARNING_BATCH_SIZE)\n",
    "test_data: tf.data.Dataset = test_data.prefetch(LEARNING_PREFETCH_SIZE)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared imports for this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "# 100x100 px, with 3 colors channels (RGB)\n",
    "INPUT_IMAGE_SHAPE: Final[Tuple] = (100, 100, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU memory limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you have a GPU installed on your machine. It's recommended to set a memory limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding() -> Model:\n",
    "    # Creating the input layer\n",
    "    input_layer = Input(shape=INPUT_IMAGE_SHAPE, name='input_image')\n",
    "\n",
    "    # First block\n",
    "    c1 = Conv2D(64, (10, 10), activation='relu')(input_layer)\n",
    "    m1 = MaxPooling2D(64, (2, 2), padding='same')(c1)\n",
    "\n",
    "    # Second bloc\n",
    "    c2 = Conv2D(128, (7, 7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2, 2), padding='same')(c2)\n",
    "\n",
    "    # Third block\n",
    "    c3 = Conv2D(128, (4, 4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2, 2), padding='same')(c3)\n",
    "\n",
    "    # Final embedding block\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "\n",
    "    return Model(inputs=[input_layer], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's try to compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_image (InputLayer)    [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 91, 91, 64)        19264     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 46, 46, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 40, 40, 128)       401536    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 20, 20, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 17, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 256)         524544    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,960,448\n",
      "Trainable params: 38,960,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating the embedding model/layer and showing the summary of it\n",
    "embedding: Model = make_embedding()\n",
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Distance Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Need to check if `arcface` will perform better than this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese L1 Distance class\n",
    "class L1Dist(Layer):\n",
    "    \n",
    "    # Init method - inheritance\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    # Smiliarity calculation\n",
    "    def call(self, input_embeddings, validation_embeddings) -> Any:\n",
    "        return tf.math.abs(input_embeddings - validation_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Siamese Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model() -> Model:\n",
    "    # Anchor image input in the network\n",
    "    input_image = Input(name='input_image', shape=INPUT_IMAGE_SHAPE)\n",
    "\n",
    "    # Validation image in the network\n",
    "    validation_image = Input(name='validation_image', shape=INPUT_IMAGE_SHAPE)\n",
    "\n",
    "    # Combine siamese distance components\n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "\n",
    "    # Classification layer\n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilation of this network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_image (InputLayer)       [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validation_image (InputLayer)  [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 4096)         38960448    ['input_image[0][0]',            \n",
      "                                                                  'validation_image[0][0]']       \n",
      "                                                                                                  \n",
      " distance (L1Dist)              (None, 4096)         0           ['embedding[0][0]',              \n",
      "                                                                  'embedding[1][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            4097        ['distance[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,964,545\n",
      "Trainable params: 38,964,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating the embedding model/layer and showing the summary of it\n",
    "siamese_model: Model = make_siamese_model()\n",
    "siamese_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps we will follow:\n",
    "1. Setup a loss function\n",
    "2. Setup an optimizer\n",
    "3. Build a Custom training step\n",
    "4. Create a Training loop\n",
    "5. Train the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports for that step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import NumpyArrayIterator\n",
    "from keras.utils import Progbar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the loss and Optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find more optiomizers in [keras optimizers](https://keras.io/api/optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
    "opt: Adam = tf.keras.optimizers.Adam(1e-4) # 0.0001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup training backup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To defend from the case where the training step is unwillingly stopped. <br />\n",
    "Let's establish checkpoints. <br />\n",
    "This means that in case the training process stopping without notice, we can continue the training process from where we stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir: str = os.path.join(WORKSPACE_DIR_PATH, '.cache', 'training_checkpoints')\n",
    "checkpoint_prefix: str = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever you need to reload the checkpoint you can just use the: `model.load(<path-to-checkpoint>)`. <br />\n",
    "This command will load the pre trained weights into the existing model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build training step function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic steps for training in one batch is as follows:\n",
    "1. Make a prediction - about the observation\n",
    "2. Calculate the loss - compare with the real answer\n",
    "3. Derive gradients\n",
    "4. Calculate new weights and apply them to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = training_data.as_numpy_iterator()\n",
    "batch: NumpyArrayIterator = test_batch.next()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We taking the training data and making it a numpy iterator. <br />\n",
    "Each of the indecies in the iterator is constructed from 3 another arrays.\n",
    "Let's write them by it's order:\n",
    "1. The anchors that we training on them\n",
    "2. The positive/negatives samples\n",
    "3. The labels of each sample (to know which sample was it)\n",
    "\n",
    "Don't forget that each the counting in those arrays starts from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchors (16): [[[[0.57843137 0.6019608  0.6019608 ]\n",
      "   [0.577451   0.6009804  0.6009804 ]\n",
      "   [0.5803922  0.6039216  0.6039216 ]\n",
      "   ...\n",
      "   [0.6188725  0.66593134 0.6502451 ]\n",
      "   [0.61960787 0.6637255  0.6480392 ]\n",
      "   [0.61960787 0.6627451  0.64705884]]\n",
      "\n",
      "  [[0.56960785 0.60490197 0.6009804 ]\n",
      "   [0.57254905 0.60784316 0.6039216 ]\n",
      "   [0.57230395 0.60759807 0.6036765 ]\n",
      "   ...\n",
      "   [0.6159314  0.6629902  0.64730394]\n",
      "   [0.61960787 0.6666667  0.6509804 ]\n",
      "   [0.61960787 0.6627451  0.64705884]]\n",
      "\n",
      "  [[0.56740195 0.60563725 0.6017157 ]\n",
      "   [0.5605392  0.5987745  0.5948529 ]\n",
      "   [0.5656863  0.6039216  0.6       ]\n",
      "   ...\n",
      "   [0.6156863  0.6627451  0.64705884]\n",
      "   [0.6164216  0.6634804  0.6477941 ]\n",
      "   [0.6166667  0.6627451  0.64705884]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.25588235 0.17352942 0.09901961]\n",
      "   [0.24191177 0.15955882 0.08504902]\n",
      "   [0.23602942 0.15514706 0.08210784]\n",
      "   ...\n",
      "   [0.1120098  0.11593137 0.05318628]\n",
      "   [0.14901961 0.15294118 0.08578432]\n",
      "   [0.1625     0.15759803 0.08995098]]\n",
      "\n",
      "  [[0.25196078 0.16960785 0.09509804]\n",
      "   [0.23284313 0.15196079 0.07892157]\n",
      "   [0.22230393 0.14730392 0.08014706]\n",
      "   ...\n",
      "   [0.10294118 0.10686275 0.04852941]\n",
      "   [0.1392157  0.14313726 0.08039216]\n",
      "   [0.1384804  0.13063726 0.07181372]]\n",
      "\n",
      "  [[0.24313726 0.16078432 0.08627451]\n",
      "   [0.23039216 0.15588236 0.08921569]\n",
      "   [0.23039216 0.15588236 0.08921569]\n",
      "   ...\n",
      "   [0.10563725 0.10955882 0.05465686]\n",
      "   [0.12941177 0.13333334 0.07254902]\n",
      "   [0.11862745 0.11078431 0.05196078]]]\n",
      "\n",
      "\n",
      " [[[0.5764706  0.6        0.6       ]\n",
      "   [0.5803922  0.6039216  0.6039216 ]\n",
      "   [0.5803922  0.6039216  0.6039216 ]\n",
      "   ...\n",
      "   [0.61960787 0.65882355 0.654902  ]\n",
      "   [0.62352943 0.6627451  0.65882355]\n",
      "   [0.61960787 0.65882355 0.654902  ]]\n",
      "\n",
      "  [[0.57254905 0.60784316 0.6039216 ]\n",
      "   [0.56960785 0.60490197 0.6009804 ]\n",
      "   [0.5686275  0.6039216  0.6       ]\n",
      "   ...\n",
      "   [0.622549   0.6666667  0.6509804 ]\n",
      "   [0.622549   0.6666667  0.6509804 ]\n",
      "   [0.61960787 0.6637255  0.6480392 ]]\n",
      "\n",
      "  [[0.56960785 0.60784316 0.6039216 ]\n",
      "   [0.56666666 0.60490197 0.6009804 ]\n",
      "   [0.5656863  0.6039216  0.6       ]\n",
      "   ...\n",
      "   [0.61495095 0.6620098  0.6463235 ]\n",
      "   [0.6159314  0.6629902  0.64730394]\n",
      "   [0.6156863  0.6627451  0.64705884]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05882353 0.05882353 0.02745098]\n",
      "   [0.06740196 0.06740196 0.03455883]\n",
      "   [0.07647059 0.07647059 0.03921569]\n",
      "   ...\n",
      "   [0.14411765 0.13725491 0.0754902 ]\n",
      "   [0.16985294 0.16593137 0.09534314]\n",
      "   [0.17843138 0.17450981 0.09607843]]\n",
      "\n",
      "  [[0.06176471 0.05882353 0.03627451]\n",
      "   [0.06372549 0.06372549 0.03235294]\n",
      "   [0.06960785 0.06960785 0.0382353 ]\n",
      "   ...\n",
      "   [0.14093137 0.13308823 0.07426471]\n",
      "   [0.16470589 0.16004902 0.09166667]\n",
      "   [0.15710784 0.15318628 0.0747549 ]]\n",
      "\n",
      "  [[0.05465686 0.05857843 0.03504902]\n",
      "   [0.05882353 0.0627451  0.0372549 ]\n",
      "   [0.06470589 0.06862745 0.0372549 ]\n",
      "   ...\n",
      "   [0.14019608 0.13235295 0.07941177]\n",
      "   [0.14901961 0.14411765 0.07647059]\n",
      "   [0.14411765 0.14019608 0.06176471]]]\n",
      "\n",
      "\n",
      " [[[0.5806373  0.6041667  0.6041667 ]\n",
      "   [0.5781863  0.6017157  0.6017157 ]\n",
      "   [0.58431375 0.60784316 0.60784316]\n",
      "   ...\n",
      "   [0.61960787 0.6627451  0.64705884]\n",
      "   [0.62352943 0.6637255  0.65686274]\n",
      "   [0.62352943 0.6627451  0.65882355]]\n",
      "\n",
      "  [[0.57254905 0.60784316 0.6039216 ]\n",
      "   [0.56960785 0.60490197 0.6009804 ]\n",
      "   [0.5754902  0.6107843  0.6068627 ]\n",
      "   ...\n",
      "   [0.6193628  0.6634804  0.6477941 ]\n",
      "   [0.6215686  0.66568625 0.65      ]\n",
      "   [0.6215686  0.6627451  0.65588236]]\n",
      "\n",
      "  [[0.56666666 0.60490197 0.6009804 ]\n",
      "   [0.5656863  0.6039216  0.6       ]\n",
      "   [0.56642157 0.6046569  0.6007353 ]\n",
      "   ...\n",
      "   [0.6156863  0.6627451  0.64705884]\n",
      "   [0.6156863  0.6627451  0.64705884]\n",
      "   [0.6156863  0.6627451  0.64705884]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.07132353 0.05955882 0.02426471]\n",
      "   [0.07941177 0.06764706 0.03235294]\n",
      "   [0.08627451 0.07450981 0.03921569]\n",
      "   ...\n",
      "   [0.15171568 0.15563725 0.08504902]\n",
      "   [0.16887255 0.16838235 0.09779412]\n",
      "   [0.16764706 0.16568628 0.09509804]]\n",
      "\n",
      "  [[0.07745098 0.06568628 0.03039216]\n",
      "   [0.08235294 0.07058824 0.03529412]\n",
      "   [0.09313726 0.08137255 0.04607843]\n",
      "   ...\n",
      "   [0.15269607 0.15661764 0.08602941]\n",
      "   [0.16519608 0.16911764 0.09852941]\n",
      "   [0.16764706 0.17156863 0.10098039]]\n",
      "\n",
      "  [[0.08529412 0.07352941 0.0382353 ]\n",
      "   [0.09117647 0.07941177 0.04411765]\n",
      "   [0.10122549 0.08946078 0.05416667]\n",
      "   ...\n",
      "   [0.15882353 0.15490197 0.08431373]\n",
      "   [0.17843138 0.17450981 0.10392157]\n",
      "   [0.18039216 0.1764706  0.10588235]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.5803922  0.6039216  0.6039216 ]\n",
      "   [0.58431375 0.60784316 0.60784316]\n",
      "   [0.58112746 0.6046569  0.6046569 ]\n",
      "   ...\n",
      "   [0.62058824 0.6637255  0.6480392 ]\n",
      "   [0.62671566 0.6698529  0.65416664]\n",
      "   [0.62058824 0.66764706 0.6519608 ]]\n",
      "\n",
      "  [[0.5688726  0.6041667  0.6002451 ]\n",
      "   [0.5686275  0.6039216  0.6       ]\n",
      "   [0.57230395 0.60759807 0.6036765 ]\n",
      "   ...\n",
      "   [0.622549   0.66568625 0.65      ]\n",
      "   [0.622549   0.66568625 0.65      ]\n",
      "   [0.62647057 0.6696078  0.65392154]]\n",
      "\n",
      "  [[0.5688726  0.6071078  0.60318625]\n",
      "   [0.5647059  0.60294116 0.5990196 ]\n",
      "   [0.5686275  0.6068627  0.60294116]\n",
      "   ...\n",
      "   [0.61960787 0.6627451  0.64705884]\n",
      "   [0.622549   0.66568625 0.65      ]\n",
      "   [0.62647057 0.6696078  0.65392154]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.10196079 0.08627451 0.04313726]\n",
      "   [0.10196079 0.08627451 0.04313726]\n",
      "   [0.10588235 0.09019608 0.04705882]\n",
      "   ...\n",
      "   [0.14803922 0.14019608 0.08137255]\n",
      "   [0.12892157 0.12107843 0.0622549 ]\n",
      "   [0.16519608 0.15735294 0.09852941]]\n",
      "\n",
      "  [[0.10196079 0.08627451 0.04313726]\n",
      "   [0.10490196 0.08921569 0.04607843]\n",
      "   [0.10588235 0.09019608 0.04705882]\n",
      "   ...\n",
      "   [0.1254902  0.11764706 0.05882353]\n",
      "   [0.1247549  0.11691176 0.05808824]\n",
      "   [0.18235295 0.17450981 0.11568628]]\n",
      "\n",
      "  [[0.10196079 0.08627451 0.04313726]\n",
      "   [0.10588235 0.09019608 0.04705882]\n",
      "   [0.10294118 0.0872549  0.04411765]\n",
      "   ...\n",
      "   [0.1122549  0.10441177 0.04558824]\n",
      "   [0.13259804 0.1247549  0.06593137]\n",
      "   [0.17156863 0.1637255  0.10490196]]]\n",
      "\n",
      "\n",
      " [[[0.5686275  0.60784316 0.6039216 ]\n",
      "   [0.5686275  0.60784316 0.6039216 ]\n",
      "   [0.5686275  0.60784316 0.6039216 ]\n",
      "   ...\n",
      "   [0.6164216  0.6634804  0.6477941 ]\n",
      "   [0.6186274  0.6627451  0.64705884]\n",
      "   [0.61960787 0.6627451  0.64705884]]\n",
      "\n",
      "  [[0.5683824  0.60759807 0.6036765 ]\n",
      "   [0.5686275  0.60784316 0.6039216 ]\n",
      "   [0.5686275  0.60784316 0.6039216 ]\n",
      "   ...\n",
      "   [0.6156863  0.6627451  0.64705884]\n",
      "   [0.6127451  0.6598039  0.64411765]\n",
      "   [0.62352943 0.6666667  0.6509804 ]]\n",
      "\n",
      "  [[0.5647059  0.6039216  0.6       ]\n",
      "   [0.5647059  0.6039216  0.6       ]\n",
      "   [0.5647059  0.6039216  0.6       ]\n",
      "   ...\n",
      "   [0.6156863  0.6627451  0.64705884]\n",
      "   [0.6156863  0.6627451  0.64705884]\n",
      "   [0.6166667  0.6627451  0.64705884]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05906863 0.05906863 0.02769608]\n",
      "   [0.07132353 0.06838235 0.0379902 ]\n",
      "   [0.08921569 0.07745098 0.04411765]\n",
      "   ...\n",
      "   [0.18284313 0.17107843 0.10441177]\n",
      "   [0.17916666 0.16740195 0.10073529]\n",
      "   [0.1860294  0.1742647  0.10759804]]\n",
      "\n",
      "  [[0.0620098  0.05906863 0.03651961]\n",
      "   [0.07132353 0.06838235 0.03651961]\n",
      "   [0.09901961 0.0872549  0.05245098]\n",
      "   ...\n",
      "   [0.16715686 0.15539216 0.08872549]\n",
      "   [0.17156863 0.15980393 0.09313726]\n",
      "   [0.17254902 0.16078432 0.09411765]]\n",
      "\n",
      "  [[0.05882353 0.05490196 0.03529412]\n",
      "   [0.06568628 0.06568628 0.03235294]\n",
      "   [0.10196079 0.09607843 0.05098039]\n",
      "   ...\n",
      "   [0.15294118 0.14117648 0.08235294]\n",
      "   [0.17254902 0.16078432 0.10196079]\n",
      "   [0.16176471 0.15       0.09117647]]]\n",
      "\n",
      "\n",
      " [[[0.56936276 0.60857844 0.6046569 ]\n",
      "   [0.5647059  0.6039216  0.6       ]\n",
      "   [0.5588235  0.5980392  0.59411764]\n",
      "   ...\n",
      "   [0.62034315 0.6634804  0.6477941 ]\n",
      "   [0.61960787 0.6598039  0.65294117]\n",
      "   [0.62352943 0.6627451  0.65882355]]\n",
      "\n",
      "  [[0.56691176 0.60612744 0.6022059 ]\n",
      "   [0.5637255  0.60294116 0.5990196 ]\n",
      "   [0.56764704 0.6068627  0.60294116]\n",
      "   ...\n",
      "   [0.6186274  0.6627451  0.64705884]\n",
      "   [0.6215686  0.66568625 0.65      ]\n",
      "   [0.622549   0.6637255  0.65686274]]\n",
      "\n",
      "  [[0.5647059  0.6039216  0.6       ]\n",
      "   [0.5644608  0.6036765  0.5997549 ]\n",
      "   [0.56764704 0.6068627  0.60294116]\n",
      "   ...\n",
      "   [0.6156863  0.6627451  0.64705884]\n",
      "   [0.6156863  0.6627451  0.64705884]\n",
      "   [0.6156863  0.6627451  0.64705884]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05098039 0.05294118 0.03039216]\n",
      "   [0.05588235 0.05784314 0.03529412]\n",
      "   [0.0627451  0.06544118 0.03627451]\n",
      "   ...\n",
      "   [0.15294118 0.14607844 0.08431373]\n",
      "   [0.16446078 0.16053921 0.08995098]\n",
      "   [0.16862746 0.16470589 0.09411765]]\n",
      "\n",
      "  [[0.05098039 0.04705882 0.02745098]\n",
      "   [0.05588235 0.05196078 0.03235294]\n",
      "   [0.06862745 0.06764706 0.03921569]\n",
      "   ...\n",
      "   [0.15318628 0.14852941 0.08014706]\n",
      "   [0.1622549  0.15833333 0.0877451 ]\n",
      "   [0.1627451  0.15588236 0.09411765]]\n",
      "\n",
      "  [[0.04779412 0.04387255 0.02426471]\n",
      "   [0.05514706 0.05122549 0.03161765]\n",
      "   [0.06862745 0.06764706 0.03921569]\n",
      "   ...\n",
      "   [0.14681372 0.14289215 0.07230392]\n",
      "   [0.14509805 0.1382353  0.07647059]\n",
      "   [0.14411765 0.13627452 0.07745098]]]]\n",
      "positive/negative samples (16): [[[[5.62745094e-01 6.09803915e-01 6.09803915e-01]\n",
      "   [5.59803903e-01 6.04901969e-01 6.05882347e-01]\n",
      "   [5.62745094e-01 6.01960778e-01 6.05882347e-01]\n",
      "   ...\n",
      "   [6.19607866e-01 6.66666687e-01 6.66666687e-01]\n",
      "   [6.17401958e-01 6.64460778e-01 6.64460778e-01]\n",
      "   [6.24509811e-01 6.71568632e-01 6.71568632e-01]]\n",
      "\n",
      "  [[5.63970566e-01 6.09068632e-01 6.10049009e-01]\n",
      "   [5.54656863e-01 6.00245118e-01 6.00980401e-01]\n",
      "   [5.62745094e-01 6.03921592e-01 6.06862724e-01]\n",
      "   ...\n",
      "   [6.15686297e-01 6.62745118e-01 6.62745118e-01]\n",
      "   [6.16421580e-01 6.63480401e-01 6.63480401e-01]\n",
      "   [6.18627429e-01 6.65686250e-01 6.65686250e-01]]\n",
      "\n",
      "  [[5.56862772e-01 5.96078455e-01 6.00000024e-01]\n",
      "   [5.56862772e-01 5.98039210e-01 6.00980401e-01]\n",
      "   [5.60784340e-01 6.06372535e-01 6.07107818e-01]\n",
      "   ...\n",
      "   [6.18627429e-01 6.65686250e-01 6.65686250e-01]\n",
      "   [6.19607866e-01 6.66666687e-01 6.66666687e-01]\n",
      "   [6.15686297e-01 6.62745118e-01 6.62745118e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[4.68137264e-02 4.68137264e-02 1.54411765e-02]\n",
      "   [5.95588237e-02 5.95588237e-02 2.67156865e-02]\n",
      "   [5.26960790e-02 5.26960790e-02 1.39705883e-02]\n",
      "   ...\n",
      "   [7.23039210e-02 7.64705911e-02 2.40196083e-02]\n",
      "   [6.17647059e-02 6.37254938e-02 1.56862754e-02]\n",
      "   [7.54901990e-02 7.54901990e-02 2.84313727e-02]]\n",
      "\n",
      "  [[4.68137264e-02 4.38725501e-02 2.13235300e-02]\n",
      "   [5.78431375e-02 5.78431375e-02 2.64705885e-02]\n",
      "   [5.63725494e-02 5.63725494e-02 2.35294122e-02]\n",
      "   ...\n",
      "   [6.71568662e-02 7.94117674e-02 2.62254905e-02]\n",
      "   [5.95588237e-02 6.74019605e-02 1.64215695e-02]\n",
      "   [6.56862780e-02 7.15686306e-02 2.74509806e-02]]\n",
      "\n",
      "  [[4.50980403e-02 4.11764719e-02 2.15686280e-02]\n",
      "   [5.49019612e-02 5.19607849e-02 2.94117648e-02]\n",
      "   [6.56862780e-02 6.56862780e-02 3.43137272e-02]\n",
      "   ...\n",
      "   [6.56862780e-02 8.13725516e-02 2.64705885e-02]\n",
      "   [5.88235296e-02 6.86274543e-02 2.25490201e-02]\n",
      "   [6.56862780e-02 7.35294148e-02 3.03921569e-02]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 3.92156886e-03 0.00000000e+00]\n",
      "   [0.00000000e+00 3.92156886e-03 0.00000000e+00]\n",
      "   [0.00000000e+00 3.92156886e-03 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 3.92156886e-03 0.00000000e+00]\n",
      "   [0.00000000e+00 3.92156886e-03 0.00000000e+00]\n",
      "   [0.00000000e+00 3.92156886e-03 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 9.80392215e-04 0.00000000e+00]\n",
      "   [0.00000000e+00 9.80392215e-04 0.00000000e+00]\n",
      "   [0.00000000e+00 9.80392215e-04 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[7.52451003e-01 5.36764681e-01 4.19117659e-01]\n",
      "   [7.57843137e-01 5.38235307e-01 4.34313715e-01]\n",
      "   [7.63970613e-01 5.39215684e-01 4.41911757e-01]\n",
      "   ...\n",
      "   [1.98039219e-01 1.95098042e-01 1.72549024e-01]\n",
      "   [2.11029410e-01 2.08088234e-01 1.85539216e-01]\n",
      "   [2.07843140e-01 2.04901963e-01 1.82352945e-01]]\n",
      "\n",
      "  [[8.21568608e-01 6.05882347e-01 4.88235295e-01]\n",
      "   [8.31372559e-01 6.16176486e-01 5.10049045e-01]\n",
      "   [8.40196073e-01 6.17647052e-01 5.13725519e-01]\n",
      "   ...\n",
      "   [1.97794124e-01 1.97794124e-01 1.60539210e-01]\n",
      "   [2.07843140e-01 2.07843140e-01 1.70588240e-01]\n",
      "   [2.10049018e-01 2.10049018e-01 1.72794119e-01]]\n",
      "\n",
      "  [[8.24509799e-01 6.12745106e-01 5.02941191e-01]\n",
      "   [8.33333313e-01 6.19607866e-01 5.18627465e-01]\n",
      "   [8.41176450e-01 6.18627429e-01 5.14215708e-01]\n",
      "   ...\n",
      "   [2.03921571e-01 2.03921571e-01 1.64705887e-01]\n",
      "   [2.03921571e-01 2.03921571e-01 1.64705887e-01]\n",
      "   [2.03921571e-01 2.03921571e-01 1.64705887e-01]]]\n",
      "\n",
      "\n",
      " [[[5.62990189e-01 6.10049009e-01 6.10049009e-01]\n",
      "   [5.62745094e-01 6.09803915e-01 6.09803915e-01]\n",
      "   [5.53921580e-01 6.00980401e-01 6.00980401e-01]\n",
      "   ...\n",
      "   [6.16911769e-01 6.63970590e-01 6.63970590e-01]\n",
      "   [6.14705861e-01 6.61764681e-01 6.61764681e-01]\n",
      "   [6.18627429e-01 6.65686250e-01 6.65686250e-01]]\n",
      "\n",
      "  [[5.59803903e-01 6.06862724e-01 6.06862724e-01]\n",
      "   [5.59068620e-01 6.06127441e-01 6.06127441e-01]\n",
      "   [5.56862772e-01 6.03921592e-01 6.03921592e-01]\n",
      "   ...\n",
      "   [6.21813715e-01 6.68872535e-01 6.68872535e-01]\n",
      "   [6.17156863e-01 6.64215684e-01 6.64215684e-01]\n",
      "   [6.19607866e-01 6.66666687e-01 6.66666687e-01]]\n",
      "\n",
      "  [[5.52941203e-01 6.00000024e-01 6.00000024e-01]\n",
      "   [5.52941203e-01 6.00000024e-01 6.00000024e-01]\n",
      "   [5.54656863e-01 6.01715684e-01 6.01715684e-01]\n",
      "   ...\n",
      "   [6.12745106e-01 6.59803927e-01 6.59803927e-01]\n",
      "   [6.16421580e-01 6.63480401e-01 6.63480401e-01]\n",
      "   [6.15686297e-01 6.62745118e-01 6.62745118e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.11029409e-01 9.53431353e-02 5.22058830e-02]\n",
      "   [1.07843138e-01 9.21568647e-02 4.90196086e-02]\n",
      "   [9.43627432e-02 7.86764696e-02 3.55392173e-02]\n",
      "   ...\n",
      "   [1.06617644e-01 1.14460781e-01 6.34803921e-02]\n",
      "   [9.68137234e-02 1.04656860e-01 5.36764711e-02]\n",
      "   [8.74999985e-02 9.53431353e-02 4.43627462e-02]]\n",
      "\n",
      "  [[9.28921551e-02 7.72058815e-02 3.40686291e-02]\n",
      "   [9.90196094e-02 8.33333358e-02 4.01960798e-02]\n",
      "   [8.60294104e-02 7.47549012e-02 2.94117648e-02]\n",
      "   ...\n",
      "   [1.09803922e-01 1.17647059e-01 6.66666701e-02]\n",
      "   [9.97548997e-02 1.07598037e-01 5.66176474e-02]\n",
      "   [8.82352963e-02 9.60784331e-02 4.50980403e-02]]\n",
      "\n",
      "  [[9.21568647e-02 7.64705911e-02 3.33333351e-02]\n",
      "   [8.65196064e-02 7.86764696e-02 3.16176489e-02]\n",
      "   [7.74509832e-02 6.96078464e-02 2.25490201e-02]\n",
      "   ...\n",
      "   [1.03676468e-01 1.11519605e-01 6.05392158e-02]\n",
      "   [1.02941178e-01 1.10784315e-01 5.98039217e-02]\n",
      "   [8.52941200e-02 9.31372568e-02 4.21568640e-02]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[6.94362760e-01 7.02205896e-01 6.59068644e-01]\n",
      "   [6.87990189e-01 6.95833325e-01 6.52696073e-01]\n",
      "   [6.79656863e-01 6.87500000e-01 6.44362748e-01]\n",
      "   ...\n",
      "   [9.65441167e-01 9.96813715e-01 9.98529434e-01]\n",
      "   [9.71323550e-01 9.94607866e-01 9.99264717e-01]\n",
      "   [9.85294104e-01 9.99754906e-01 9.93137240e-01]]\n",
      "\n",
      "  [[6.45098031e-01 6.49019599e-01 6.19607866e-01]\n",
      "   [6.54166639e-01 6.58088207e-01 6.28676474e-01]\n",
      "   [6.61764681e-01 6.65686250e-01 6.36274517e-01]\n",
      "   ...\n",
      "   [8.97794127e-01 9.26225483e-01 9.62499976e-01]\n",
      "   [9.20343161e-01 9.56617653e-01 9.88970578e-01]\n",
      "   [9.50490177e-01 9.82843161e-01 9.97794092e-01]]\n",
      "\n",
      "  [[6.56862736e-01 6.60784304e-01 6.40196085e-01]\n",
      "   [6.58088207e-01 6.62009776e-01 6.41421556e-01]\n",
      "   [6.73774481e-01 6.77696049e-01 6.57107830e-01]\n",
      "   ...\n",
      "   [7.29656875e-01 7.55637228e-01 8.05882335e-01]\n",
      "   [7.67156839e-01 8.23039234e-01 8.83823514e-01]\n",
      "   [8.52696061e-01 9.11764681e-01 9.69117641e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[3.77941191e-01 3.89705896e-01 3.54411751e-01]\n",
      "   [4.05882359e-01 4.16666657e-01 3.71568620e-01]\n",
      "   [3.53921562e-01 3.56617659e-01 3.07107836e-01]\n",
      "   ...\n",
      "   [2.85539210e-01 3.48284304e-01 4.07107830e-01]\n",
      "   [4.60539222e-01 5.23284316e-01 5.82107842e-01]\n",
      "   [4.85784322e-01 5.48529387e-01 6.07352912e-01]]\n",
      "\n",
      "  [[4.76470590e-01 4.88235295e-01 4.52941179e-01]\n",
      "   [4.98284310e-01 5.09068608e-01 4.65931386e-01]\n",
      "   [5.79411745e-01 5.84313750e-01 5.30392170e-01]\n",
      "   ...\n",
      "   [2.24509805e-01 2.87254900e-01 3.46078426e-01]\n",
      "   [3.79901975e-01 4.42647070e-01 5.01470566e-01]\n",
      "   [4.95588243e-01 5.58333337e-01 6.17156863e-01]]\n",
      "\n",
      "  [[5.47303915e-01 5.59068620e-01 5.23774505e-01]\n",
      "   [5.34558833e-01 5.45343161e-01 5.02205908e-01]\n",
      "   [5.31372547e-01 5.36274493e-01 4.82352942e-01]\n",
      "   ...\n",
      "   [2.99509794e-01 3.62254888e-01 4.21078444e-01]\n",
      "   [2.27696076e-01 2.90441185e-01 3.49264711e-01]\n",
      "   [4.27696079e-01 4.90441173e-01 5.49264729e-01]]]\n",
      "\n",
      "\n",
      " [[[3.03921580e-01 3.35294127e-01 3.78431380e-01]\n",
      "   [2.69607842e-01 2.91176468e-01 3.38235289e-01]\n",
      "   [2.55637258e-01 2.71323532e-01 3.15441191e-01]\n",
      "   ...\n",
      "   [1.06862746e-01 1.50000006e-01 1.25980392e-01]\n",
      "   [1.44362748e-01 1.93382353e-01 1.59068629e-01]\n",
      "   [1.56862751e-01 2.07843140e-01 1.72549024e-01]]\n",
      "\n",
      "  [[3.14705878e-01 3.47058833e-01 4.00000006e-01]\n",
      "   [2.82107830e-01 3.11519593e-01 3.63480389e-01]\n",
      "   [2.68872559e-01 2.86519617e-01 3.33578438e-01]\n",
      "   ...\n",
      "   [1.22549020e-01 1.57843143e-01 1.47549018e-01]\n",
      "   [1.33088231e-01 1.76225483e-01 1.56127453e-01]\n",
      "   [9.70588252e-02 1.46078438e-01 1.21568628e-01]]\n",
      "\n",
      "  [[3.33088249e-01 3.77205878e-01 4.38970596e-01]\n",
      "   [2.83823520e-01 3.18627447e-01 3.77696067e-01]\n",
      "   [2.52205878e-01 2.77205884e-01 3.31372559e-01]\n",
      "   ...\n",
      "   [1.14705883e-01 1.41176477e-01 1.32352948e-01]\n",
      "   [1.33578435e-01 1.70343131e-01 1.51960790e-01]\n",
      "   [1.08088233e-01 1.51225492e-01 1.29656866e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[6.45833313e-01 6.22303903e-01 5.20343125e-01]\n",
      "   [5.95343113e-01 5.89460790e-01 4.92401958e-01]\n",
      "   [5.56372523e-01 5.67156851e-01 4.83823538e-01]\n",
      "   ...\n",
      "   [2.52450984e-02 5.66176474e-02 1.05637252e-01]\n",
      "   [4.77941185e-02 8.21078420e-02 1.19362742e-01]\n",
      "   [4.01960798e-02 7.54901990e-02 1.10784315e-01]]\n",
      "\n",
      "  [[6.61519587e-01 6.45343125e-01 5.33823550e-01]\n",
      "   [6.55147076e-01 6.51470602e-01 5.46323538e-01]\n",
      "   [6.27451003e-01 6.41176462e-01 5.45588255e-01]\n",
      "   ...\n",
      "   [4.21568640e-02 7.35294148e-02 1.22549020e-01]\n",
      "   [5.00000007e-02 8.43137279e-02 1.21568628e-01]\n",
      "   [4.70588244e-02 8.23529437e-02 1.17647059e-01]]\n",
      "\n",
      "  [[6.75490201e-01 6.59803927e-01 5.46078444e-01]\n",
      "   [6.70588255e-01 6.67647064e-01 5.51960766e-01]\n",
      "   [6.58823550e-01 6.67647064e-01 5.60784340e-01]\n",
      "   ...\n",
      "   [4.82843146e-02 7.96568617e-02 1.28676474e-01]\n",
      "   [5.22058830e-02 8.65196064e-02 1.23774506e-01]\n",
      "   [5.09803928e-02 8.62745121e-02 1.21568628e-01]]]\n",
      "\n",
      "\n",
      " [[[7.62254894e-02 7.23039210e-02 5.66176474e-02]\n",
      "   [8.65196064e-02 9.04411748e-02 7.08333328e-02]\n",
      "   [8.92156884e-02 9.31372568e-02 7.35294148e-02]\n",
      "   ...\n",
      "   [3.06127459e-01 2.98284322e-01 2.02205881e-01]\n",
      "   [2.82107830e-01 2.74264693e-01 1.89950988e-01]\n",
      "   [2.51960784e-01 2.40196079e-01 1.65686280e-01]]\n",
      "\n",
      "  [[6.34803921e-02 5.95588237e-02 4.38725501e-02]\n",
      "   [7.35294148e-02 7.74509832e-02 5.78431375e-02]\n",
      "   [8.23529437e-02 8.62745121e-02 6.66666701e-02]\n",
      "   ...\n",
      "   [2.99019605e-01 2.91176468e-01 1.95098042e-01]\n",
      "   [2.83333331e-01 2.75490195e-01 1.91176474e-01]\n",
      "   [2.63970584e-01 2.56127447e-01 1.73774511e-01]]\n",
      "\n",
      "  [[7.35294148e-02 6.96078464e-02 5.39215691e-02]\n",
      "   [6.96078464e-02 7.35294148e-02 5.39215691e-02]\n",
      "   [7.25490227e-02 7.64705911e-02 5.68627454e-02]\n",
      "   ...\n",
      "   [3.17892164e-01 3.12254906e-01 2.08088234e-01]\n",
      "   [2.95588225e-01 2.87745088e-01 1.97549015e-01]\n",
      "   [2.71568626e-01 2.63725489e-01 1.81372553e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.23284292e-01 9.61519599e-01 8.84558797e-01]\n",
      "   [9.45098042e-01 9.46568608e-01 8.96323502e-01]\n",
      "   [9.47794139e-01 9.53676462e-01 9.05637264e-01]\n",
      "   ...\n",
      "   [2.50245094e-01 2.73774505e-01 2.34558821e-01]\n",
      "   [2.46078432e-01 2.69607842e-01 2.30392158e-01]\n",
      "   [2.49754906e-01 2.73284316e-01 2.34068632e-01]]\n",
      "\n",
      "  [[9.11764681e-01 9.49264705e-01 8.80392134e-01]\n",
      "   [9.29411769e-01 9.35294092e-01 8.85294139e-01]\n",
      "   [9.54166651e-01 9.57843125e-01 9.04901981e-01]\n",
      "   ...\n",
      "   [2.45098040e-01 2.59803921e-01 2.23529413e-01]\n",
      "   [2.66911775e-01 2.81617641e-01 2.45343134e-01]\n",
      "   [2.45343134e-01 2.60049015e-01 2.23774508e-01]]\n",
      "\n",
      "  [[9.06617641e-01 9.43872571e-01 8.77205908e-01]\n",
      "   [9.28186297e-01 9.41911757e-01 8.87990177e-01]\n",
      "   [9.76715684e-01 9.81617630e-01 9.26715672e-01]\n",
      "   ...\n",
      "   [2.49754906e-01 2.61519611e-01 2.26225495e-01]\n",
      "   [2.49509797e-01 2.61274517e-01 2.25980386e-01]\n",
      "   [2.43137255e-01 2.54901975e-01 2.19607845e-01]]]]\n",
      "labels (16): [1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(f'anchors ({len(batch[0])}):', batch[0])\n",
    "print(f'positive/negative samples ({len(batch[1])}):', batch[1])\n",
    "print(f'labels ({len(batch[2])}):', batch[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the value of the `X` aka. `features`. <br/>\n",
    "Each batch in the dataset is comprised of 16 samples each of which contains an anchor image, positive or negative image and a label.\n",
    "\n",
    "`(2, 16, 100, 100, 3)` is the representation of:\n",
    "* `2` - components(datasets)\n",
    "* `16` - samples in each component\n",
    "* `100, 100, 3` - is the shpae of each sample (the image -> 2d array with an array of 3 colors init RGB)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 16, 100, 100, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(batch[:2]).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the `y` aka. `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the training step"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_step()` function used to define the training loop of specifc batch.\n",
    "\n",
    "*For your knowledge:\n",
    "The optimizer here is calculating and propagating the new wieghts using Adam's optimization, a varient of gradient descent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch: NumpyArrayIterator) -> BinaryCrossentropy:\n",
    "    # Capturing all the functions in the training process (for the backpropagation)\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Get anchor and positive/negative image\n",
    "        X = batch[:2] # `X` the convention for the features (source data)\n",
    "        y = batch[2] # `y` is the convention for label (tag / real result)\n",
    "\n",
    "        # Forward pass\n",
    "        # It's very important to set the Training parameter to True for enabling specific layers in the neural network\n",
    "        y_hat = siamese_model(X, training=True)\n",
    "        \n",
    "        # Calculating loss\n",
    "        # `y_hat` is convention for the prediction of y the model has predicted\n",
    "        loss: BinaryCrossentropy = binary_cross_loss(y, y_hat)\n",
    "\n",
    "    # Calculate gradients (for specific values of the weights)\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "\n",
    "    # Calculate updated wieghts and apply to siamese model -> Applying the changes into the model\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build training loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `train()` function will contain the training logic of all the batches in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data: tf.data.Dataset, EPOCHS):\n",
    "    # Loop through epochs\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        print(f'Epoch {epoch}/{EPOCHS}')\n",
    "        progbar = Progbar(len(data))\n",
    "\n",
    "        # Loop through each batch\n",
    "        for idx, batch in enumerate(data):\n",
    "            # Run train step here\n",
    "            train_step(batch)\n",
    "            progbar.update(idx + 1)\n",
    "\n",
    "        # Save checkpoints\n",
    "        if epoch % 10 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 10:52:05.318574: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2023-02-05 10:52:07.391660: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-05 10:52:07.392539: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-05 10:52:07.392581: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-02-05 10:52:07.393341: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-05 10:52:07.393427: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 8s 135ms/step\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 2s 111ms/step\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 2s 112ms/step\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 2s 112ms/step\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 2s 112ms/step\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 2s 111ms/step\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 2s 111ms/step\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 2s 111ms/step\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 2s 111ms/step\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 2s 112ms/step\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 2s 112ms/step\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 2s 112ms/step\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 2s 112ms/step\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 2s 112ms/step\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 2s 113ms/step\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 2s 113ms/step\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 2s 113ms/step\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 2s 113ms/step\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 2s 113ms/step\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 2s 113ms/step\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 2s 113ms/step\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 2s 113ms/step\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 2s 113ms/step\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 2s 113ms/step\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 2s 113ms/step\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 2s 113ms/step\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 2s 113ms/step\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 2s 114ms/step\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 2s 114ms/step\n"
     ]
    }
   ],
   "source": [
    "EPOCHS: Final[int] = 50\n",
    "train(training_data, EPOCHS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalueate Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how the model we just created is performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metrics from keras\n",
    "from keras.metrics import Precision, Recall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what these metrics does? \n",
    "\n",
    "Precision - Demonstrates what proportion of positive identification were actually correct. <br />\n",
    "Recall - Shows what proprtion of actual positives were identified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a batch of test data\n",
    "test_input, test_val, y_true = test_data.as_numpy_iterator().next()\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.5373587e-10],\n",
       "       [1.0000000e+00],\n",
       "       [2.9035010e-09],\n",
       "       [3.0661291e-09],\n",
       "       [2.0087561e-04],\n",
       "       [9.9999988e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9981457e-01],\n",
       "       [9.9999928e-01],\n",
       "       [9.9999917e-01],\n",
       "       [1.0328871e-08],\n",
       "       [9.9999845e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9999082e-01],\n",
       "       [3.3621811e-10],\n",
       "       [9.9995697e-01]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making some predicitions\n",
    "y_hat = siamese_model.predict([test_input, test_val])\n",
    "y_hat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post processing results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the way to create an array in python's way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1 if predictions > 0.4 else 0 for predictions in y_hat]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code snippet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code generally looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for predictions in y_hat:\n",
    "    if predictions > 0.4:\n",
    "        res.append(1)\n",
    "    else:\n",
    "        res.append(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or just use the metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the metric object\n",
    "m = Recall()\n",
    "m.update_state(y_true, y_hat) # Calculating recall value\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Precision()\n",
    "m.update_state(y_true, y_hat) # Calculating the precision value\n",
    "m.result().numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look at the predictions [post processing results](#Post-processing-results) section array, and change the test samples you want to see in the plot below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TEST_SAMPLE_INDEX: Final[int] = 0\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "fig.suptitle(f'Test anchor and Test validation \\nPredicted: {y_hat[TEST_SAMPLE_INDEX]} Real: {y_true[TEST_SAMPLE_INDEX]}')\n",
    "\n",
    "ax1.imshow(test_input[TEST_SAMPLE_INDEX]) # Index of test sample\n",
    "ax1.set_title('Test input')\n",
    "ax2.imshow(test_val[TEST_SAMPLE_INDEX]) # Index of test sample\n",
    "ax2.set_title('Test validation')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_FILENAME: Final[str] = 'siamesemodel.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Save the weights\n",
    "siamese_model.save(path.join(OUTPUTS_PATH, WEIGHTS_FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Model reload from file\n",
    "model = tf.keras.models.load_model(\n",
    "    os.path.join(OUTPUTS_PATH, WEIGHTS_FILENAME), \n",
    "    \n",
    "    # Adding the custom layers we created on our own\n",
    "    custom_objects={\n",
    "        'L1Dist': L1Dist, # Custom layer that need to be loaded\n",
    "        'BinaryCrossentropy': tf.losses.BinaryCrossentropy\n",
    "    }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with weights only"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_weights()` function can be used to load the weights also. <br />\n",
    "The `save_weights()` function saves only the weights, the `save()` function saves optimizer state as well."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real time test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FYI: This phase will use the webcam in your computer. Like the previous phases. <br />\n",
    "In case you are using remote machine to execute this code, you will need to run this phase on **your computer**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adgenda:\n",
    "* Setup verification images (that you will provide)\n",
    "* Build Verification function \n",
    "* Perform recognition in real time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the tutorial we will actually verify each photo against the \"verified photos\" of each people we want to recognize. <br/>\n",
    "This method is not optimized for multiple people we will want to be able to recognize.\n",
    "\n",
    "That's about this. Stay tuned for the next step."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating folders for the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All necessary folders created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "APP_WORKSPACE_DIR_PATH: Final[str] = 'app_workspace'\n",
    "INPUT_IMAGES_DIR_PATH: Final[str] = path.join(APP_WORKSPACE_DIR_PATH, 'input_images')\n",
    "VERIFICATION_IMAGES_DIR_PATH: Final[str] = path.join(APP_WORKSPACE_DIR_PATH, 'verification_images')\n",
    "\n",
    "os.makedirs(APP_WORKSPACE_DIR_PATH, exist_ok=True)\n",
    "os.makedirs(INPUT_IMAGES_DIR_PATH, exist_ok=True)\n",
    "os.makedirs(VERIFICATION_IMAGES_DIR_PATH, exist_ok=True)\n",
    "\n",
    "print('All necessary folders created')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we created those folders let's start to fill it with data. <br/>\n",
    "For this test let's copy 50 images from the positive folder and paste them into the folder placed in `VERIFICATION_IMAGES_DIR_PATH`.\n",
    "\n",
    "**Don't forget!** you can se as many images as you like, but at this point the test using just 50. <br/>\n",
    "Keep in mind - Everything is a tradeoff, the bigger your verification set is - the slower the model will be."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(model: Model, detection_threshold: float, verification_threshold: float) -> Tuple[list, bool]:\n",
    "    '''\n",
    "        This function verifies the given frame (that like the assumption it will contain a face) \n",
    "        and will check whther the face at the frame is the same person as the faces at the verification_dir\n",
    "\n",
    "        args:\n",
    "            model: Model - The tensorflow model that we created\n",
    "            detection_threashold: float - \n",
    "            verification_threshold: float - A threshold for how much verification images required to be true\n",
    "\n",
    "        returns:\n",
    "            A tuple containing - \n",
    "                0. List of the results of each test (in that test 50 results)\n",
    "                1. Wether this input image is the same person (verified) \n",
    "    '''\n",
    "    verification_images: list[str] = os.listdir(VERIFICATION_IMAGES_DIR_PATH)\n",
    "    results = []\n",
    "    \n",
    "    for image in verification_images:\n",
    "        input_img = preprocess(os.path.join(INPUT_IMAGES_DIR_PATH, 'input_image.jpg'))\n",
    "        validation_img = preprocess(os.path.join(VERIFICATION_IMAGES_DIR_PATH, image))\n",
    "\n",
    "        # Doing the same as `preprocess_twin()`\n",
    "        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
    "        results.append(result)\n",
    "\n",
    "    # Detection Threshold: Metric above which a prediction is considered as positive\n",
    "    detection = np.sum(np.array(results) > detection_threshold)\n",
    "\n",
    "    # Verification Threshold: Proportion of positive predictions / total positive samples\n",
    "    verification = detection / len(verification_images)\n",
    "    verified = verification > verification_threshold\n",
    "\n",
    "    return results, verified"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV Real Time Verificaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 887ms/step\n",
      "1/1 [==============================] - 1s 519ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "Time took: 24.1194486618042\n",
      "Verified: True\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "Time took: 21.211853742599487\n",
      "Verified: False\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "Time took: 20.95662260055542\n",
      "Verified: False\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 445ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "1/1 [==============================] - 1s 638ms/step\n",
      "1/1 [==============================] - 1s 559ms/step\n",
      "1/1 [==============================] - 1s 576ms/step\n",
      "1/1 [==============================] - 1s 637ms/step\n",
      "1/1 [==============================] - 1s 617ms/step\n",
      "1/1 [==============================] - 1s 617ms/step\n",
      "1/1 [==============================] - 1s 543ms/step\n",
      "1/1 [==============================] - 1s 559ms/step\n",
      "1/1 [==============================] - 1s 642ms/step\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "1/1 [==============================] - 0s 492ms/step\n",
      "1/1 [==============================] - 0s 478ms/step\n",
      "1/1 [==============================] - 1s 573ms/step\n",
      "1/1 [==============================] - 0s 494ms/step\n",
      "1/1 [==============================] - 1s 576ms/step\n",
      "1/1 [==============================] - 1s 543ms/step\n",
      "1/1 [==============================] - 1s 566ms/step\n",
      "1/1 [==============================] - 1s 646ms/step\n",
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 1s 649ms/step\n",
      "1/1 [==============================] - 0s 496ms/step\n",
      "1/1 [==============================] - 1s 533ms/step\n",
      "1/1 [==============================] - 1s 550ms/step\n",
      "1/1 [==============================] - 1s 542ms/step\n",
      "1/1 [==============================] - 1s 550ms/step\n",
      "1/1 [==============================] - 1s 581ms/step\n",
      "1/1 [==============================] - 1s 589ms/step\n",
      "1/1 [==============================] - 1s 557ms/step\n",
      "1/1 [==============================] - 0s 486ms/step\n",
      "1/1 [==============================] - 1s 556ms/step\n",
      "1/1 [==============================] - 1s 534ms/step\n",
      "1/1 [==============================] - 1s 580ms/step\n",
      "1/1 [==============================] - 1s 593ms/step\n",
      "1/1 [==============================] - 1s 586ms/step\n",
      "1/1 [==============================] - 1s 530ms/step\n",
      "1/1 [==============================] - 1s 687ms/step\n",
      "1/1 [==============================] - 1s 549ms/step\n",
      "1/1 [==============================] - 1s 506ms/step\n",
      "1/1 [==============================] - 1s 515ms/step\n",
      "1/1 [==============================] - 1s 615ms/step\n",
      "Time took: 35.15633845329285\n",
      "Verified: False\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "Time took: 21.716094493865967\n",
      "Verified: False\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 473ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "Time took: 21.609988927841187\n",
      "Verified: True\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Cut a 250x250 pixels crop from the original feed\n",
    "    start_x: int = 200\n",
    "    start_y: int = 120\n",
    "    height: int = start_y + 250\n",
    "    width: int = start_x + 250\n",
    "    frame = frame[start_x:width, start_y:height, :]\n",
    "\n",
    "    cv2.imshow('Verification', frame)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
    "        # TODO: Change it to work with frame instead of files\n",
    "        # Save input image into the input images folder\n",
    "        cv2.imwrite(os.path.join(INPUT_IMAGES_DIR_PATH, 'input_image.jpg'), frame)\n",
    "        starting_time = time.time()\n",
    "        results, verified = verify(model, .4, .5)\n",
    "        \n",
    "        print('Time took:', time.time() - starting_time)\n",
    "        print('Verified:', verified)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7bb6876993b2b103376e027649eaab835bc81729f875a1d0f5f440f0228b14c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
